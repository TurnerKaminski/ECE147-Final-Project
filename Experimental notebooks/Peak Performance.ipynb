{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os.path\n",
    "import numpy as np\n",
    "\n",
    "# Load in data, this assumed you have a folder in env named data\n",
    "data_dir = \"data\"\n",
    "X_test = np.load(os.path.join(data_dir, \"X_test.npy\"))\n",
    "y_test = np.load(os.path.join(data_dir, \"y_test.npy\"))\n",
    "person_test = np.load(os.path.join(data_dir, \"person_test.npy\")).squeeze(axis=1)\n",
    "X_train_valid = np.load(os.path.join(data_dir, \"X_train_valid.npy\"))\n",
    "y_train_valid = np.load(os.path.join(data_dir, \"y_train_valid.npy\"))\n",
    "person_train_valid = np.load(os.path.join(data_dir, \"person_train_valid.npy\")).squeeze(axis=1)\n",
    "\n",
    "# Predefine some useful variables and fix data a bit\n",
    "n_class = len(set(y_train_valid))\n",
    "n_trials = 5\n",
    "min_y = min(y_train_valid)\n",
    "y_train_valid = y_train_valid - min_y\n",
    "y_test = y_test - min_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 22, 1000)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid shape: (2115,)\n",
      "Person test shape: (443,)\n"
     ]
    }
   ],
   "source": [
    "# Validate data loaded in correctly and print shapes\n",
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'. format (X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "# Define random seed so that we can reproduce results\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# This is for macbook M1, if you have intel I think you use cuda not mps\n",
    "# Research what works for your device and change the torch.device\n",
    "device = torch.device(\"cuda\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the models and functions\n",
    "from models import *\n",
    "from trainer import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data loader for all subjects\n",
    "\n",
    "# Convert data to tensors\n",
    "X_tensor_full = torch.FloatTensor(X_test[:,:,:400])\n",
    "y_tensor_full = torch.LongTensor(y_test)\n",
    "\n",
    "# Combine X and y into a TensorDataset\n",
    "dataset_full = TensorDataset(X_tensor_full, y_tensor_full)\n",
    "\n",
    "# Prepare dataloaders\n",
    "test_dataloader_full = DataLoader(dataset_full, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble\n",
    "\n",
    "Test the effect of ensembling models using max voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Goal of this Notebook is Maximum Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_models = []\n",
    "\n",
    "for i in range(5):\n",
    "    cnn = CNN(input_size=X_train_valid[:,:,:400].shape[1:], N=n_class).to(device)\n",
    "    fit(cnn, X_train_valid[:,:,:400], y_train_valid, device, epochs=400)\n",
    "    ensemble_models.append(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now training the CNN model\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255a380addf34a61b1012c6970ca1667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best valid accuracy: 0.65485\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c1a3782f1348d3bbe0f8fa34cb32e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best valid accuracy: 0.66903\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6439221168ea4ea4b47988e0013050c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best valid accuracy: 0.70213\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f3a42cc4304c8a9d8b35588bcd8366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best valid accuracy: 0.69976\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c9c6babd8f44bf894404955dd0935e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best valid accuracy: 0.7234\n",
      "Accuracy of ensemble: 0.68849\n"
     ]
    }
   ],
   "source": [
    "# CNN\n",
    "y_pred_CNN = []\n",
    "\n",
    "print(\"Now training the CNN model\\n\")\n",
    "for i in range(5):\n",
    "    cnn = CNN(input_size=X_train_valid[:,:,:300].shape[1:], N=n_class).to(device)\n",
    "    fit(cnn, X_train_valid[:,:,:300], y_train_valid, device, epochs=100)\n",
    "    _, y_pred = evaluate(cnn, test_dataloader_full, device)\n",
    "    y_pred_CNN.append(y_pred)\n",
    "\n",
    "# Lets try max voting since thats used for classification tasks\n",
    "def max_voting(*args):\n",
    "    \"\"\"\n",
    "    Perform max voting ensemble for multiple classifiers.\n",
    "    \n",
    "    Args:\n",
    "    *args: Arrays of predicted class labels from each classifier.\n",
    "    \n",
    "    Returns:\n",
    "    Ensemble predictions based on max voting.\n",
    "    \"\"\"\n",
    "    # Concatenate predicted labels along axis 1\n",
    "    concatenated_predictions = np.concatenate(args, axis=0)\n",
    "    \n",
    "    # Find the most frequent prediction for each sample\n",
    "    ensemble_predictions = np.array([np.argmax(np.bincount(sample_predictions)) for sample_predictions in concatenated_predictions.T])\n",
    "\n",
    "    return ensemble_predictions\n",
    "\n",
    "# Now lets try it out\n",
    "# ensemble_predictions = max_voting(y_pred_CNN, y_pred_LSTM, y_pred_CRNN, y_pred_CRNN_2)\n",
    "ensemble_predictions = max_voting(y_pred_CNN)\n",
    "\n",
    "# Get accuracy of ensemble\n",
    "correct = np.sum(ensemble_predictions == y_test)\n",
    "total = len(y_test)\n",
    "accuracy_ensemble = correct/total\n",
    "\n",
    "print(\"Accuracy of ensemble: \" + str(round(accuracy_ensemble, 5)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cc54b9e43af7a0c7fb4d06dbdd44e5ca6fb86b76a909759481753182cba9a8da"
  },
  "kernelspec": {
   "display_name": "Python 3.10.13 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
